import common

from nltk.stem.porter import PorterStemmer

# http://stackoverflow.com/questions/26126442/
stemmer = PorterStemmer()

def search(keyword):
  """Search related books/courses from the keyword

  keyword: A string. Search keyword.
  returns: A list of integers representing IDs of related items

  Currently the items are generated by union of bigrams.
  """

  # Possibly TODO: normalize keywords (stopwords & stemming & cases)
  uni_keywords = common.simpl_stopwords_split(keyword.lower())
  #uni_keywords = [stemmer.stem(w) for w in uni_keywords]
  if len(uni_keywords) > 1:
    bi_keywords = [" ".join(ws) for ws in zip(uni_keywords, uni_keywords[1:])]
  else:
    bi_keywords = uni_keywords

  idset = []
  for keyword2 in bi_keywords:
    for vocab in common.ITEM_VOCABS.itervalues():
      if keyword2 in vocab["vocabs"]:
        idset.append(vocab[u"id"])

  return list(set(idset))

if __name__ == "__main__":
  print "item_search test"
  print "python\n", search(u"python")
  print "\nmachine learning"
  print search(u"machine learning")
